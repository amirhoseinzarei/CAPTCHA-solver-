{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-09-07T08:39:44.453895Z",
     "iopub.status.busy": "2022-09-07T08:39:44.452895Z",
     "iopub.status.idle": "2022-09-07T08:39:51.065460Z",
     "shell.execute_reply": "2022-09-07T08:39:51.065460Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf version:  2.7.0\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from CTClayer import CTCLayer\n",
    "from SquareRootScheduler import SquareRootScheduler\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "print('tf version: ', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T08:39:51.070458Z",
     "iopub.status.busy": "2022-09-07T08:39:51.069457Z",
     "iopub.status.idle": "2022-09-07T08:39:51.080452Z",
     "shell.execute_reply": "2022-09-07T08:39:51.080452Z"
    }
   },
   "outputs": [],
   "source": [
    "#number of epochs\n",
    "epochs = 200\n",
    "# Batch size for training and validation\n",
    "batch_size = 16\n",
    "\n",
    "# Desired image dimensions\n",
    "img_width = 200\n",
    "img_height = 50\n",
    "\n",
    "# Factor by which the image is going to be downsampled\n",
    "# by the convolutional blocks. We will be using two\n",
    "# convolution blocks and each block will have\n",
    "# a pooling layer which downsample the features by a factor of 2.\n",
    "# Hence total downsampling factor would be 4.\n",
    "downsample_factor = 4\n",
    "\n",
    "\n",
    "early_stopping_patience = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T08:39:51.105437Z",
     "iopub.status.busy": "2022-09-07T08:39:51.105437Z",
     "iopub.status.idle": "2022-09-07T08:39:51.111434Z",
     "shell.execute_reply": "2022-09-07T08:39:51.110434Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function creates our OCR model for reading captchas\n",
    "\"\"\"\n",
    "def build_model():\n",
    "    \"\"\"\n",
    "    :return model\n",
    "    \"\"\"    \n",
    "    # Inputs to the model\n",
    "    input_img = layers.Input(\n",
    "        shape=(img_width, img_height, 1), name=\"image\", dtype=\"float32\"\n",
    "    )\n",
    "    labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n",
    "\n",
    "    # First conv block\n",
    "    x = layers.Conv2D(\n",
    "        32,\n",
    "        (3, 3),\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        padding=\"same\",\n",
    "        name=\"Conv1\",\n",
    "    )(input_img)\n",
    "    x = layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
    "\n",
    "    # Second conv block\n",
    "    x = layers.Conv2D(\n",
    "        64,\n",
    "        (3, 3),\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        padding=\"same\",\n",
    "        name=\"Conv2\",\n",
    "    )(x)\n",
    "    x = layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
    "\n",
    "    # We have used two max pool with pool size and strides 2.\n",
    "    # Hence, downsampled feature maps are 4x smaller. The number of\n",
    "    # filters in the last layer is 64. Reshape accordingly before\n",
    "    # passing the output to the GRU part of the model\n",
    "    new_shape = ((img_width // 4), (img_height // 4) * 64)\n",
    "    x = layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    # GRUs\n",
    "    x = layers.Bidirectional(layers.GRU(128, return_sequences=True, dropout=0.25))(x)\n",
    "    x = layers.Bidirectional(layers.GRU(128, return_sequences=True, dropout=0.25))(x)\n",
    "    x = layers.Bidirectional(layers.GRU(64, return_sequences=True, dropout=0.25))(x)\n",
    "\n",
    "    # Output layer\n",
    "    x = layers.Dense(\n",
    "        len(utils.char_to_num.get_vocabulary()) + 1, activation=\"softmax\", name=\"dense2\"\n",
    "    )(x)\n",
    "\n",
    "    # Add CTC layer for calculating CTC loss at each step\n",
    "    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.models.Model(\n",
    "        inputs=[input_img, labels], outputs=output, name=\"ocr_model\"\n",
    "    )\n",
    "    # Optimizer\n",
    "    opt = keras.optimizers.Adam(learning_rate=3e-4)\n",
    "    # Compile the model and return\n",
    "    model.compile(optimizer=opt)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T08:39:51.118429Z",
     "iopub.status.busy": "2022-09-07T08:39:51.116431Z",
     "iopub.status.idle": "2022-09-07T08:39:51.393272Z",
     "shell.execute_reply": "2022-09-07T08:39:51.393272Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset,validation_dataset=utils.getData(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T08:39:51.403266Z",
     "iopub.status.busy": "2022-09-07T08:39:51.399270Z",
     "iopub.status.idle": "2022-09-07T08:46:09.829121Z",
     "shell.execute_reply": "2022-09-07T08:46:09.829121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ocr_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image (InputLayer)             [(None, 200, 50, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 200, 50, 32)  320         ['image[0][0]']                  \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 100, 25, 32)  0           ['Conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv2 (Conv2D)                 (None, 100, 25, 64)  18496       ['pool1[0][0]']                  \n",
      "                                                                                                  \n",
      " pool2 (MaxPooling2D)           (None, 50, 12, 64)   0           ['Conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 50, 768)      0           ['pool2[0][0]']                  \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 50, 64)       49216       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 50, 64)       0           ['dense1[0][0]']                 \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 50, 256)      148992      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 50, 256)     296448      ['bidirectional[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 50, 128)     123648      ['bidirectional_1[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " label (InputLayer)             [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dense2 (Dense)                 (None, 50, 21)       2709        ['bidirectional_2[0][0]']        \n",
      "                                                                                                  \n",
      " ctc_loss (CTCLayer)            (None, 50, 21)       0           ['label[0][0]',                  \n",
      "                                                                  'dense2[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 639,829\n",
      "Trainable params: 639,829\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "59/59 [==============================] - 18s 118ms/step - loss: 25.3843 - val_loss: 16.9858 - lr: 3.0000e-04\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 4s 73ms/step - loss: 16.3731 - val_loss: 16.6694 - lr: 2.1213e-04\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 4s 72ms/step - loss: 16.3534 - val_loss: 16.6526 - lr: 1.7321e-04\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 4s 71ms/step - loss: 16.3539 - val_loss: 16.6248 - lr: 1.5000e-04\n",
      "Epoch 5/200\n",
      "59/59 [==============================] - 4s 72ms/step - loss: 16.3241 - val_loss: 16.6170 - lr: 1.3416e-04\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 4s 71ms/step - loss: 16.3174 - val_loss: 16.6217 - lr: 1.2247e-04\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - 4s 71ms/step - loss: 16.3238 - val_loss: 16.5829 - lr: 1.1339e-04\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 4s 72ms/step - loss: 16.3007 - val_loss: 16.6066 - lr: 1.0607e-04\n",
      "Epoch 9/200\n",
      "59/59 [==============================] - 4s 71ms/step - loss: 16.3001 - val_loss: 16.5924 - lr: 1.0000e-04\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 4s 72ms/step - loss: 16.2937 - val_loss: 16.5712 - lr: 9.4868e-05\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 4s 72ms/step - loss: 16.2748 - val_loss: 16.5310 - lr: 9.0453e-05\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 4s 75ms/step - loss: 16.2598 - val_loss: 16.5503 - lr: 8.6603e-05\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 4s 76ms/step - loss: 16.2427 - val_loss: 16.5442 - lr: 8.3205e-05\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 4s 76ms/step - loss: 16.2615 - val_loss: 16.5006 - lr: 8.0178e-05\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 4s 76ms/step - loss: 16.2342 - val_loss: 16.4845 - lr: 7.7460e-05\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 16.2052 - val_loss: 16.4611 - lr: 7.5000e-05\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 4s 76ms/step - loss: 16.1691 - val_loss: 16.4500 - lr: 7.2761e-05\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 16.1141 - val_loss: 16.3873 - lr: 7.0711e-05\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 4s 76ms/step - loss: 15.9961 - val_loss: 16.2579 - lr: 6.8825e-05\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 15.7121 - val_loss: 15.7532 - lr: 6.7082e-05\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 15.3087 - val_loss: 15.0601 - lr: 6.5465e-05\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 5s 76ms/step - loss: 14.8085 - val_loss: 14.5808 - lr: 6.3960e-05\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 5s 76ms/step - loss: 14.3121 - val_loss: 13.9131 - lr: 6.2554e-05\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 4s 74ms/step - loss: 13.7861 - val_loss: 13.2486 - lr: 6.1237e-05\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 4s 76ms/step - loss: 13.2687 - val_loss: 12.7010 - lr: 6.0000e-05\n",
      "Epoch 26/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 12.7120 - val_loss: 11.9742 - lr: 5.8835e-05\n",
      "Epoch 27/200\n",
      "59/59 [==============================] - 5s 82ms/step - loss: 12.1457 - val_loss: 11.1992 - lr: 5.7735e-05\n",
      "Epoch 28/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 11.4941 - val_loss: 10.3506 - lr: 5.6695e-05\n",
      "Epoch 29/200\n",
      "59/59 [==============================] - 4s 75ms/step - loss: 10.7618 - val_loss: 9.3998 - lr: 5.5709e-05\n",
      "Epoch 30/200\n",
      "59/59 [==============================] - 4s 70ms/step - loss: 9.9257 - val_loss: 8.4187 - lr: 5.4772e-05\n",
      "Epoch 31/200\n",
      "59/59 [==============================] - 4s 70ms/step - loss: 9.0894 - val_loss: 7.3787 - lr: 5.3882e-05\n",
      "Epoch 32/200\n",
      "59/59 [==============================] - 4s 71ms/step - loss: 8.1729 - val_loss: 6.3941 - lr: 5.3033e-05\n",
      "Epoch 33/200\n",
      "59/59 [==============================] - 4s 71ms/step - loss: 7.3360 - val_loss: 5.5019 - lr: 5.2223e-05\n",
      "Epoch 34/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 6.5041 - val_loss: 4.6956 - lr: 5.1450e-05\n",
      "Epoch 35/200\n",
      "59/59 [==============================] - 6s 97ms/step - loss: 5.7275 - val_loss: 4.0111 - lr: 5.0709e-05\n",
      "Epoch 36/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 5.0453 - val_loss: 3.4792 - lr: 5.0000e-05\n",
      "Epoch 37/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 4.5254 - val_loss: 3.0371 - lr: 4.9320e-05\n",
      "Epoch 38/200\n",
      "59/59 [==============================] - 4s 75ms/step - loss: 4.0335 - val_loss: 2.6631 - lr: 4.8666e-05\n",
      "Epoch 39/200\n",
      "59/59 [==============================] - 4s 75ms/step - loss: 3.6187 - val_loss: 2.3931 - lr: 4.8038e-05\n",
      "Epoch 40/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 3.3062 - val_loss: 2.1729 - lr: 4.7434e-05\n",
      "Epoch 41/200\n",
      "59/59 [==============================] - 4s 74ms/step - loss: 2.9928 - val_loss: 1.9970 - lr: 4.6852e-05\n",
      "Epoch 42/200\n",
      "59/59 [==============================] - 4s 75ms/step - loss: 2.7402 - val_loss: 1.8118 - lr: 4.6291e-05\n",
      "Epoch 43/200\n",
      "59/59 [==============================] - 4s 74ms/step - loss: 2.5105 - val_loss: 1.6739 - lr: 4.5750e-05\n",
      "Epoch 44/200\n",
      "59/59 [==============================] - 4s 76ms/step - loss: 2.3317 - val_loss: 1.5576 - lr: 4.5227e-05\n",
      "Epoch 45/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 2.1451 - val_loss: 1.4693 - lr: 4.4721e-05\n",
      "Epoch 46/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 2.0184 - val_loss: 1.3427 - lr: 4.4233e-05\n",
      "Epoch 47/200\n",
      "59/59 [==============================] - 4s 76ms/step - loss: 1.9239 - val_loss: 1.2706 - lr: 4.3759e-05\n",
      "Epoch 48/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 1.7891 - val_loss: 1.1903 - lr: 4.3301e-05\n",
      "Epoch 49/200\n",
      "59/59 [==============================] - 4s 73ms/step - loss: 1.6590 - val_loss: 1.1397 - lr: 4.2857e-05\n",
      "Epoch 50/200\n",
      "59/59 [==============================] - 4s 75ms/step - loss: 1.6079 - val_loss: 1.0765 - lr: 4.2426e-05\n",
      "Epoch 51/200\n",
      "59/59 [==============================] - 4s 76ms/step - loss: 1.4881 - val_loss: 1.0288 - lr: 4.2008e-05\n",
      "Epoch 52/200\n",
      "59/59 [==============================] - 4s 74ms/step - loss: 1.4090 - val_loss: 1.0069 - lr: 4.1603e-05\n",
      "Epoch 53/200\n",
      "59/59 [==============================] - 4s 73ms/step - loss: 1.3388 - val_loss: 0.9243 - lr: 4.1208e-05\n",
      "Epoch 54/200\n",
      "59/59 [==============================] - 4s 73ms/step - loss: 1.2957 - val_loss: 0.8756 - lr: 4.0825e-05\n",
      "Epoch 55/200\n",
      "59/59 [==============================] - 4s 73ms/step - loss: 1.2738 - val_loss: 0.8379 - lr: 4.0452e-05\n",
      "Epoch 56/200\n",
      "59/59 [==============================] - 4s 74ms/step - loss: 1.1626 - val_loss: 0.8228 - lr: 4.0089e-05\n",
      "Epoch 57/200\n",
      "59/59 [==============================] - 4s 73ms/step - loss: 1.1271 - val_loss: 0.7577 - lr: 3.9736e-05\n",
      "Epoch 58/200\n",
      "59/59 [==============================] - 5s 80ms/step - loss: 1.0750 - val_loss: 0.7031 - lr: 3.9392e-05\n",
      "Epoch 59/200\n",
      "59/59 [==============================] - 5s 83ms/step - loss: 1.0146 - val_loss: 0.6647 - lr: 3.9057e-05\n",
      "Epoch 60/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.9763 - val_loss: 0.6475 - lr: 3.8730e-05\n",
      "Epoch 61/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.9488 - val_loss: 0.5797 - lr: 3.8411e-05\n",
      "Epoch 62/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.8816 - val_loss: 0.5449 - lr: 3.8100e-05\n",
      "Epoch 63/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.8578 - val_loss: 0.5117 - lr: 3.7796e-05\n",
      "Epoch 64/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.8138 - val_loss: 0.4878 - lr: 3.7500e-05\n",
      "Epoch 65/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.7787 - val_loss: 0.4457 - lr: 3.7210e-05\n",
      "Epoch 66/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.7530 - val_loss: 0.4058 - lr: 3.6927e-05\n",
      "Epoch 67/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.6939 - val_loss: 0.3706 - lr: 3.6651e-05\n",
      "Epoch 68/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.6455 - val_loss: 0.3390 - lr: 3.6380e-05\n",
      "Epoch 69/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.5818 - val_loss: 0.3195 - lr: 3.6116e-05\n",
      "Epoch 70/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.5807 - val_loss: 0.2952 - lr: 3.5857e-05\n",
      "Epoch 71/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.5308 - val_loss: 0.2684 - lr: 3.5603e-05\n",
      "Epoch 72/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.5029 - val_loss: 0.2494 - lr: 3.5355e-05\n",
      "Epoch 73/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.4595 - val_loss: 0.2392 - lr: 3.5112e-05\n",
      "Epoch 74/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.4564 - val_loss: 0.2280 - lr: 3.4874e-05\n",
      "Epoch 75/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.4221 - val_loss: 0.2163 - lr: 3.4641e-05\n",
      "Epoch 76/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.4002 - val_loss: 0.2006 - lr: 3.4412e-05\n",
      "Epoch 77/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.3729 - val_loss: 0.2010 - lr: 3.4188e-05\n",
      "Epoch 78/200\n",
      "59/59 [==============================] - 5s 76ms/step - loss: 0.3380 - val_loss: 0.1912 - lr: 3.3968e-05\n",
      "Epoch 79/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.3542 - val_loss: 0.1809 - lr: 3.3753e-05\n",
      "Epoch 80/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.3151 - val_loss: 0.1754 - lr: 3.3541e-05\n",
      "Epoch 81/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.3289 - val_loss: 0.1732 - lr: 3.3333e-05\n",
      "Epoch 82/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.3019 - val_loss: 0.1601 - lr: 3.3129e-05\n",
      "Epoch 83/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.2931 - val_loss: 0.1632 - lr: 3.2929e-05\n",
      "Epoch 84/200\n",
      "59/59 [==============================] - 5s 76ms/step - loss: 0.2811 - val_loss: 0.1605 - lr: 3.2733e-05\n",
      "Epoch 85/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.2638 - val_loss: 0.1618 - lr: 3.2540e-05\n",
      "Epoch 86/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.2433 - val_loss: 0.1547 - lr: 3.2350e-05\n",
      "Epoch 87/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.2436 - val_loss: 0.1556 - lr: 3.2163e-05\n",
      "Epoch 88/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.2217 - val_loss: 0.1490 - lr: 3.1980e-05\n",
      "Epoch 89/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.2193 - val_loss: 0.1435 - lr: 3.1800e-05\n",
      "Epoch 90/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.2128 - val_loss: 0.1400 - lr: 3.1623e-05\n",
      "Epoch 91/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.2228 - val_loss: 0.1487 - lr: 3.1449e-05\n",
      "Epoch 92/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.2101 - val_loss: 0.1418 - lr: 3.1277e-05\n",
      "Epoch 93/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.1926 - val_loss: 0.1384 - lr: 3.1109e-05\n",
      "Epoch 94/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.1775 - val_loss: 0.1337 - lr: 3.0943e-05\n",
      "Epoch 95/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.1835 - val_loss: 0.1341 - lr: 3.0779e-05\n",
      "Epoch 96/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.1707 - val_loss: 0.1458 - lr: 3.0619e-05\n",
      "Epoch 97/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.1758 - val_loss: 0.1406 - lr: 3.0460e-05\n",
      "Epoch 98/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.1553 - val_loss: 0.1391 - lr: 3.0305e-05\n",
      "Epoch 99/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.1668 - val_loss: 0.1462 - lr: 3.0151e-05\n",
      "Epoch 100/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.1756 - val_loss: 0.1383 - lr: 3.0000e-05\n",
      "Epoch 101/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.1590 - val_loss: 0.1326 - lr: 2.9851e-05\n",
      "Epoch 102/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.1356 - val_loss: 0.1403 - lr: 2.9704e-05\n",
      "Epoch 103/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.1402 - val_loss: 0.1338 - lr: 2.9560e-05\n",
      "Epoch 104/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.1423 - val_loss: 0.1378 - lr: 2.9417e-05\n",
      "Epoch 105/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.1354 - val_loss: 0.1379 - lr: 2.9277e-05\n",
      "Epoch 106/200\n",
      "59/59 [==============================] - 5s 77ms/step - loss: 0.1339 - val_loss: 0.1450 - lr: 2.9139e-05\n",
      "Epoch 107/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.1334 - val_loss: 0.1372 - lr: 2.9002e-05\n",
      "Epoch 108/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.1234 - val_loss: 0.1377 - lr: 2.8868e-05\n",
      "Epoch 109/200\n",
      "59/59 [==============================] - 5s 81ms/step - loss: 0.1146 - val_loss: 0.1303 - lr: 2.8735e-05\n",
      "Epoch 110/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.1169 - val_loss: 0.1353 - lr: 2.8604e-05\n",
      "Epoch 111/200\n",
      "59/59 [==============================] - 5s 81ms/step - loss: 0.1165 - val_loss: 0.1277 - lr: 2.8475e-05\n",
      "Epoch 112/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.1120 - val_loss: 0.1367 - lr: 2.8347e-05\n",
      "Epoch 113/200\n",
      "59/59 [==============================] - 5s 80ms/step - loss: 0.1223 - val_loss: 0.1353 - lr: 2.8222e-05\n",
      "Epoch 114/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.1175 - val_loss: 0.1344 - lr: 2.8098e-05\n",
      "Epoch 115/200\n",
      "59/59 [==============================] - 5s 80ms/step - loss: 0.1031 - val_loss: 0.1308 - lr: 2.7975e-05\n",
      "Epoch 116/200\n",
      "59/59 [==============================] - 5s 80ms/step - loss: 0.0960 - val_loss: 0.1310 - lr: 2.7854e-05\n",
      "Epoch 117/200\n",
      "59/59 [==============================] - 5s 82ms/step - loss: 0.1108 - val_loss: 0.1330 - lr: 2.7735e-05\n",
      "Epoch 118/200\n",
      "59/59 [==============================] - 5s 80ms/step - loss: 0.0978 - val_loss: 0.1271 - lr: 2.7617e-05\n",
      "Epoch 119/200\n",
      "59/59 [==============================] - 5s 81ms/step - loss: 0.0956 - val_loss: 0.1246 - lr: 2.7501e-05\n",
      "Epoch 120/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.0935 - val_loss: 0.1328 - lr: 2.7386e-05\n",
      "Epoch 121/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.0961 - val_loss: 0.1453 - lr: 2.7273e-05\n",
      "Epoch 122/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.0905 - val_loss: 0.1267 - lr: 2.7161e-05\n",
      "Epoch 123/200\n",
      "59/59 [==============================] - 5s 80ms/step - loss: 0.0902 - val_loss: 0.1306 - lr: 2.7050e-05\n",
      "Epoch 124/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.0803 - val_loss: 0.1368 - lr: 2.6941e-05\n",
      "Epoch 125/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.0740 - val_loss: 0.1346 - lr: 2.6833e-05\n",
      "Epoch 126/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.0825 - val_loss: 0.1347 - lr: 2.6726e-05\n",
      "Epoch 127/200\n",
      "59/59 [==============================] - 5s 79ms/step - loss: 0.0837 - val_loss: 0.1383 - lr: 2.6621e-05\n",
      "Epoch 128/200\n",
      "59/59 [==============================] - 5s 78ms/step - loss: 0.0799 - val_loss: 0.1400 - lr: 2.6517e-05\n",
      "Epoch 129/200\n",
      "59/59 [==============================] - 5s 80ms/step - loss: 0.0769 - val_loss: 0.1247 - lr: 2.6414e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the model\n",
    "model = build_model()\n",
    "model.summary()\n",
    "plot_model(model,show_shapes=True)\n",
    "# Add early stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True\n",
    ")\n",
    "\n",
    "#Learning Rate Scheduler\n",
    "scheduler = SquareRootScheduler(lr=3e-4)\n",
    "lrate = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping,lrate]\n",
    ")\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b232ef68f376693bdcf87328848ac700fa35fc2ea05767b7229c565d8395edc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
